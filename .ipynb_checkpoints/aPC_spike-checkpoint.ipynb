{
 "metadata": {
  "name": "",
  "signature": "sha256:691ed7d496ff12e83a3d4846b11798041b0494ff91b53830d6c63709f13e5922"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Resources\n",
      "\n",
      "Review article: [Dimensionality reduction for large-scale neural recordings](files/CunninghamYuNN2014.pdf)\n",
      "\n",
      "Model for analysis: [A Topological Paradigm for Hippocampal Spatial Map Formation Using Persistent Homology ](files/dabaghian12.pdf)\n",
      "\n",
      "Review of persistent homology: [Topology and data](http://www.ams.org/journals/bull/2009-46-02/S0273-0979-09-01249-X/S0273-0979-09-01249-X.pdf)\n",
      "\n",
      "<img src=\"files/untitled3.png\">\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Setup\n",
      "\n",
      "The data exists in three Matlab files, `spikeIDtiming.mat`, `trialdata.mat`, and `20150205_datafile002_194_mn_metadata.mat`.\n",
      "\n",
      "`metadata.rt` is the sampling rate (Hz). All timings--both for trial structure and for spike events--are in sample number, so you'll need this quantity to relate to seconds.\n",
      "\n",
      "`metadata.numsamples` is the total number of samples in the dataset (per channel, of course). this number divided by rt gives you total time of the experiment\n",
      "\n",
      "`trialDataStruct.UOIs` lists the ID number of each one of the units (which is what we call neurons). There are 68 in this dataset.\n",
      "\n",
      "`trialDataStruct.odorEpochs` are the timings (in sample number) of the onset (column 0) and offset (column 1) of each one of the trials (odor pulses), of which there were 280 (one trial onset/offset for each row)\n",
      "\n",
      "`trialDataStruct.valveID` is the identity of the odorant on each one of the 280 trials, in the order in which they were presented (so there is a straight forward correspondence between valveID and odorEpochs). Note that 6 is a blank trial (no odorant).\n",
      "\n",
      "`spikeIDtiming.mat` contains the unit ID (column 0) and time of occurrence (column 1) for all of the spikes in the dataset, of which there a bit more than half a million."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# scipy.io is not needed since it does not actually implement the HDF5 / 7.3 interface \n",
      "import numpy as np\n",
      "import h5py # for Matlab 7.3+ files\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "file = h5py.File('spikeIDtiming.mat', 'r') # 'r' indicates read-only\n",
      "data = file['spikeIDtiming']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data is an array of 622,291 pairs (ID, time_of_spike):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "array([       38,       292,       405, ..., 349478973, 349480295,\n",
        "       349480737], dtype=uint32)"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Eventually we will want to turn this into some sort of point cloud data before applying persistent homology to it. For now let's just read off some of this data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plots\n",
      "\n",
      "\"\"\"def plotImage(arr):\n",
      "    fig = plt.figure(figsize=(5,5), dpi=80, facecolor='w',edgecolor='w',frameon=True)\n",
      "    imAx = plt.imshow(arr, origin='lower', interpolation='nearest')\n",
      "    fig.colorbar(imAx, pad=0.01, fraction=0.1, shrink=1.00, aspect=20)\n",
      "\n",
      "def plotHistogram(arr):\n",
      "    fig = plt.figure(figsize=(5,5), dpi=80, facecolor='w',edgecolor='w',frameon=True)\n",
      "    plt.hist(arr.flatten(), bins=100)\n",
      "\n",
      "eventNumber = 0\n",
      "file = h5py.File('20150205_datafile002_194_mn_metadata.mat', 'r')\n",
      "dataset = file['#refs#']['c']\n",
      "arr1ev = dataset[eventNumber]\n",
      "\n",
      "#plotImage(arr1ev)\n",
      "plotHistogram(arr1ev)\n",
      "plt.show()\n",
      "file.close()\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Read off metadata*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metadata = h5py.File('20150205_datafile002_194_mn_metadata.mat', 'r')\n",
      "# metadata.keys() has '#refs#' (index?) and 'metadata'\n",
      "# metadata['metadata'].keys() has 'rt' and 'numSamples'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "samplingHz = metadata['metadata/rt'][0][0]\n",
      "numSamples = metadata['metadata/numSamples'][0][0]\n",
      "duration = numSamples / samplingHz\n",
      "\n",
      "print \"Duration of the experiment: \" + str(duration) + \" seconds = \" + \\\n",
      "    str(duration / 60) + \" minutes\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Duration of the experiment: 11649.3595667 seconds = 194.155992778 minutes\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "\"def plotImage(arr):\\n    fig = plt.figure(figsize=(5,5), dpi=80, facecolor='w',edgecolor='w',frameon=True)\\n    imAx = plt.imshow(arr, origin='lower', interpolation='nearest')\\n    fig.colorbar(imAx, pad=0.01, fraction=0.1, shrink=1.00, aspect=20)\\n\\ndef plotHistogram(arr):\\n    fig = plt.figure(figsize=(5,5), dpi=80, facecolor='w',edgecolor='w',frameon=True)\\n    plt.hist(arr.flatten(), bins=100)\\n\\neventNumber = 0\\nfile = h5py.File('20150205_datafile002_194_mn_metadata.mat', 'r')\\ndataset = file['#refs#']['c']\\narr1ev = dataset[eventNumber]\\n\\n#plotImage(arr1ev)\\nplotHistogram(arr1ev)\\nplt.show()\\nfile.close()\\n\""
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Analysis\n",
      "(2/21) Attempted to setup the Dionysus persistent homology package, but received a consistent error `Fatal Python error: PyEval_SaveThread: NULL tstate`. I believe this has to do with the Python bindings.\n",
      "\n",
      "(2/22) Attempting to use the Holes package (a port of javaPlex, after which I will default to using Plex in Matlab)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}